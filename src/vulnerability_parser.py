from __future__ import annotations

import re
import time
from typing import Optional, Dict, List

import pandas as pd
from bs4 import BeautifulSoup


def cvss_edited(raw: str) -> tuple[str, str]:
    try:
        number = re.sub(r'[^\d,.]', '', raw)
        number = number.replace(',', '.')
        value = float(number)
        score = f'{value:.1f}'
        if value < 4.0:
            severity = 'LOW'
        elif value < 7.0:
            severity = 'MEDIUM'
        elif value < 9.0:
            severity = 'HIGH'
        else:
            severity = 'CRITICAL'
        return score, severity
    except Exception:
        return 'N/A', 'N/A'


def find_main_table_with_retry(
    soup: BeautifulSoup,
    max_attempts: int = 2,
    delay: int = 5,
):
    for attempt in range(max_attempts):
        main_table = soup.find('table', class_='table')
        if main_table:
            return main_table
        if attempt < max_attempts - 1:
            time.sleep(delay)
    return None


class VulnerabilityParser:
    def parse_vulnerability_data(self, html: str, url: str) -> pd.DataFrame:
        try:
            soup = BeautifulSoup(html, 'html.parser')
            data_list = self._extract_data(soup, url)
            if data_list and isinstance(data_list[0], dict) and 'should_stop' in data_list[0]:
                return pd.DataFrame(data_list)
            return pd.DataFrame(data_list)
        except Exception:
            return pd.DataFrame([{'should_stop': True}])

    def _extract_data(self, soup: BeautifulSoup, url: str) -> List[Dict[str, str]]:
        data_list: List[Dict[str, str]] = []

        main_table = find_main_table_with_retry(soup)
        if not main_table:
            return [{'should_skip': True}]

        vendors: List[str] = []
        products: List[str] = []
        type_: Optional[str] = None

        rows = list(main_table.find_all('tr'))
        if len(rows) <= 1:
            return [{'should_skip': True}]

        for row in rows[1:]:
            cells = row.find_all('td')
            if len(cells) < 4:
                continue

            vendor_span = cells[0].find('span')
            vendor = vendor_span.get_text(strip=True) if vendor_span else 'N/A'

            product_span = cells[1].find('span')
            product_name = product_span.get_text(strip=True) if product_span else 'N/A'

            version_text = ''
            if len(cells) > 2:
                version_span = cells[2].find('span')
                if version_span:
                    version_text = version_span.get_text(strip=True)

            raw_type = cells[3].get_text(strip=True)
            type_ = re.sub(r'([а-я])([А-Я])', r'\1 \2', raw_type)

            base_product = product_name
            if vendor and product_name:
                pattern = r'^\s*' + re.escape(vendor) + r'[\s,\u00A0\-]+'
                cleaned = re.sub(pattern, '', product_name, flags=re.IGNORECASE).strip()
                base_product = cleaned or product_name.strip()

            full_product = f'{base_product} {version_text}'.strip()
            vendors.append(vendor)
            products.append(full_product)

        vendor_all_list = [
            v for v in vendors
            if v and v.upper() != 'N/A'
        ]
        vendor_all = ', '.join(dict.fromkeys(vendor_all_list))

        product_all_list = [
            p for p in products
            if p and not re.fullmatch(r'(?:N/?A|NA|None|null)', p, flags=re.I)
        ]
        product_all = ', '.join(dict.fromkeys(product_all_list))

        if vendor_all and product_all:
            data_list.append(
                {
                    'Вендор': vendor_all,
                    'Продукт': product_all,
                    'Тип': type_ or '',
                }
            )
        else:
            return [{'should_skip': True}]

        title: Optional[str] = None
        cvss_score: str = 'N/A'
        severity: str = 'N/A'
        cve: str = 'N/A'
        date_published: Optional[str] = None
        date_detected: Optional[str] = None

        for row in rows:
            cells = row.find_all('td')
            if len(cells) < 2:
                continue

            header = cells[0].get_text(strip=True).lower()
            value = cells[1].get_text(' ', strip=True)

            if 'описание уязвимости' in header:
                title = value
            elif 'уровень опасности уязвимости' in header:
                m = re.search(
                    r'cvss 3\.\d+ составляет (\d+(?:,\d+)?)',
                    value,
                    flags=re.I,
                )
                if m:
                    cvss_score, severity = cvss_edited(m.group(1))
            elif 'идентификаторы других систем описаний уязвимостей' in header:
                ids = re.findall(r'CVE-\d{4}-\d{4,}', value)
                if ids:
                    cve = ', '.join(ids)
            elif 'дата публикации' in header:
                date_published = value
            elif 'дата выявления' in header:
                date_detected = value

        bdu_id = url.rstrip('/').rsplit('/', 1)[-1] if '/' in url else url

        for d in data_list:
            d['CVE'] = cve
            d['CVSS'] = cvss_score
            d['Критичность'] = severity
            d['BDU-ID'] = bdu_id
            d['Источник'] = url
            d['Заголовок'] = (title or '').replace('\xa0', ' ').strip()
            if date_published:
                d['Дата публикации'] = date_published
            if date_detected:
                d['Дата выявления'] = date_detected

        if not data_list:
            return [{'should_stop': True}]
        return data_list
