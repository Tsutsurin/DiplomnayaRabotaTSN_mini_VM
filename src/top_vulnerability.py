# -*- coding: utf-8 -*-
import re
from typing import Optional, Dict, List

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from src.html_parser import BrowserHTMLParser

NEWS_URL = 'https://bdu.fstec.ru/news/summary'
NEWS_LINK_TEXT = 'Обновлены сведения об уязвимостях программного обеспечения'

def get_latest_bdu_id(headless: bool = True, wait_seconds: int = 30) -> str:
    parser = BrowserHTMLParser(headless=headless)
    d = parser.driver
    try:
        d.get('https://bdu.fstec.ru/vul')
        WebDriverWait(d, wait_seconds).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '#vuls'))
        )
        row_selectors: List[str] = [
            '#vuls table.table-vuls tbody tr',
            '#vuls table tbody tr',
            'table.table-vuls tbody tr',
            'table tbody tr',
        ]
        def any_rows(driver):
            for sel in row_selectors:
                if driver.find_elements(By.CSS_SELECTOR, sel):
                    return True
            return False
        WebDriverWait(d, wait_seconds).until(any_rows)

        first_row = None
        for sel in row_selectors:
            rows = d.find_elements(By.CSS_SELECTOR, sel)
            if rows:
                first_row = rows[0]
                break
        if not first_row:
            raise TimeoutException('Не найдена строка таблицы уязвимостей.')

        link = None
        for link_sel in ('td a.confirm-vul', "td a[href*='/vul/']"):
            els = first_row.find_elements(By.CSS_SELECTOR, link_sel)
            if els:
                link = els[0]
                break
        if not link:
            raise NoSuchElementException('Не найдена ссылка с ID в первой строке.')

        text = (link.text or '').strip()
        if text.upper().startswith('BDU:'):
            return text.split(':', 1)[-1].strip()

        href = link.get_attribute('href') or ''
        m = re.search(r'/vul/(\d{4}-\d+)', href)
        if m:
            return m.group(1)
        raise NoSuchElementException('Не смогли извлечь ID из первой строки.')
    finally:
        parser.close()

def _extract_count(html: str) -> Optional[int]:
    m = re.search(r'Добавлена\s+информация\s+о\s+(\d+)\s+уязвимост', html, flags=re.IGNORECASE)
    if not m:
        return None
    try:
        return int(m.group(1))
    except Exception:
        return None

def get_latest_from_news_count(headless: bool = True, wait_seconds: int = 25) -> Dict[str, Optional[object]]:
    parser = BrowserHTMLParser(headless=headless)
    d = parser.driver
    try:
        d.get(NEWS_URL)
        WebDriverWait(d, wait_seconds).until(
            EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, NEWS_LINK_TEXT))
        )
        links = d.find_elements(By.PARTIAL_LINK_TEXT, NEWS_LINK_TEXT)
        if not links:
            raise TimeoutException('Нет ссылок на новости об обновлениях уязвимостей.')

        href = links[0].get_attribute('href')
        if href:
            d.get(href)
        else:
            links[0].click()

        WebDriverWait(d, wait_seconds).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '.news, .content, .container-fluid, .row'))
        )
        count = _extract_count(d.page_source)
        return {'count': count, 'news_url': d.current_url}
    finally:
        parser.close()
